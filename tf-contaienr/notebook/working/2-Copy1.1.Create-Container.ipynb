{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Script-mode Custom Training Container (2)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to build and use a custom Docker container for training with Amazon SageMaker that leverages on the <strong>Script Mode</strong> execution that is implemented by the sagemaker-training-toolkit library. Reference documentation is available at https://github.com/aws/sagemaker-training-toolkit.\n",
    "\n",
    "The difference from the first example is that we are not copying the training code during the Docker build process, and we are loading them dynamically from Amazon S3 (this feature is implemented through the sagemaker-training-toolkit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining some variables like the current execution role, the ECR repository that we are going to use for pushing the custom Docker container and a default Amazon S3 bucket to be used by Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "057716757052\n",
      "ap-northeast-2\n",
      "arn:aws:iam::057716757052:role/service-role/AmazonSageMaker-ExecutionRole-20210120T193680\n",
      "sagemaker-ap-northeast-2-057716757052\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "ecr_namespace = 'sagemaker-training-containers/'\n",
    "prefix = 'tf-script-mode-container-2'\n",
    "\n",
    "ecr_repository_name = ecr_namespace + prefix\n",
    "role = get_execution_role()\n",
    "account_id = role.split(':')[4]\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(account_id)\n",
    "print(region)\n",
    "print(role)\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the Dockerfile which defines the statements for building our script-mode custom training container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mFROM\u001b[39;49;00m \u001b[33mtensorflow/tensorflow:2.2.0rc2-gpu-py3-jupyter\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# Install sagemaker-training toolkit to enable SageMaker Python SDK\u001b[39;49;00m\n",
      "\u001b[34mRUN\u001b[39;49;00m pip3 install sagemaker-training\n"
     ]
    }
   ],
   "source": [
    "! pygmentize ../docker/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At high-level the Dockerfile specifies the following operations for building this container:\n",
    "<ul>\n",
    "    <li>Start from Ubuntu 16.04</li>\n",
    "    <li>Define some variables to be used at build time to install Python 3</li>\n",
    "    <li>Some handful libraries are installed with apt-get</li>\n",
    "    <li>We then install Python 3 and create a symbolic link</li>\n",
    "    <li>We install some Python libraries like numpy, pandas, ScikitLearn, etc.</li>\n",
    "    <li>We set e few environment variables, including PYTHONUNBUFFERED which is used to avoid buffering Python standard output (useful for logging)</li>\n",
    "    <li>We install the <strong>sagemaker-training-toolkit</strong> library</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Build and push the container</h3>\n",
    "We are now ready to build this container and push it to Amazon ECR. This task is executed using a shell script stored in the ../script/ folder. Let's take a look at this script and then execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mACCOUNT_ID\u001b[39;49;00m=\u001b[31m$1\u001b[39;49;00m\n",
      "\u001b[31mREGION\u001b[39;49;00m=\u001b[31m$2\u001b[39;49;00m\n",
      "\u001b[31mREPO_NAME\u001b[39;49;00m=\u001b[31m$3\u001b[39;49;00m\n",
      "\n",
      "docker build -f ../docker/Dockerfile -t \u001b[31m$REPO_NAME\u001b[39;49;00m ../docker\n",
      "\n",
      "docker tag \u001b[31m$REPO_NAME\u001b[39;49;00m \u001b[31m$ACCOUNT_ID\u001b[39;49;00m.dkr.ecr.\u001b[31m$REGION\u001b[39;49;00m.amazonaws.com/\u001b[31m$REPO_NAME\u001b[39;49;00m:latest\n",
      "\n",
      "\u001b[34m$(\u001b[39;49;00maws ecr get-login --no-include-email --registry-ids \u001b[31m$ACCOUNT_ID\u001b[39;49;00m\u001b[34m)\u001b[39;49;00m\n",
      "\n",
      "aws ecr describe-repositories --repository-names \u001b[31m$REPO_NAME\u001b[39;49;00m || aws ecr create-repository --repository-name \u001b[31m$REPO_NAME\u001b[39;49;00m\n",
      "\n",
      "docker push \u001b[31m$ACCOUNT_ID\u001b[39;49;00m.dkr.ecr.\u001b[31m$REGION\u001b[39;49;00m.amazonaws.com/\u001b[31m$REPO_NAME\u001b[39;49;00m:latest\n"
     ]
    }
   ],
   "source": [
    "! pygmentize ../scripts/build_and_push.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>--------------------------------------------------------------------------------------------------------------------</h3>\n",
    "\n",
    "The script builds the Docker container, then creates the repository if it does not exist, and finally pushes the container to the ECR repository. The build task requires a few minutes to be executed the first time, then Docker caches build outputs to be reused for the subsequent build operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! ../scripts/build_and_push.sh $account_id $region $ecr_repository_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training with Amazon SageMaker</h3>\n",
    "\n",
    "Once we have correctly pushed our container to Amazon ECR, we are ready to start training with Amazon SageMaker, which requires the ECR path to the Docker container used for training as parameter for starting a training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "057716757052.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-training-containers/tf-script-mode-container-2:latest\n"
     ]
    }
   ],
   "source": [
    "container_image_uri = '{0}.dkr.ecr.{1}.amazonaws.com/{2}:latest'.format(account_id, region, ecr_repository_name)\n",
    "print(container_image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the purpose of this example is explaining how to build custom script-mode containers, we are not going to train a real model. The script that will be executed does not define a specific training logic; it just outputs the configurations injected by SageMaker and implements a dummy training loop. Training data is also dummy. Let's analyze the script first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m absolute_import\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mutils\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m save_model_artifacts, print_files_in_path\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(hp1, hp2, hp3, train_channel, validation_channel):\n",
      "\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mList of files in train channel: \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    print_files_in_path(os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    \n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mList of files in validation channel: \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    print_files_in_path(os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_VALIDATION\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    \n",
      "    \u001b[37m# Dummy net.\u001b[39;49;00m\n",
      "    net = \u001b[34mNone\u001b[39;49;00m\n",
      "        \n",
      "    \u001b[37m# Run training loop.\u001b[39;49;00m\n",
      "    epochs = \u001b[34m5\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m x \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(epochs):\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mRunning epoch \u001b[39;49;00m\u001b[33m{0}\u001b[39;49;00m\u001b[33m...\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(x))\n",
      "\n",
      "        time.sleep(\u001b[34m30\u001b[39;49;00m)\n",
      "\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mCompleted epoch \u001b[39;49;00m\u001b[33m{0}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(x))\n",
      "        \n",
      "    \u001b[37m# At the end of the training loop, we have to save model artifacts.\u001b[39;49;00m\n",
      "    model_dir = os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "    save_model_artifacts(model_dir + \u001b[33m'\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, net)\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "\n",
      "    parser = argparse.ArgumentParser()\n",
      "    \n",
      "    \u001b[37m# sagemaker-containers passes hyperparameters as arguments\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hp1\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hp2\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m50\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hp3\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.1\u001b[39;49;00m)\n",
      "    \n",
      "    \u001b[37m# This is a way to pass additional arguments when running as a script\u001b[39;49;00m\n",
      "    \u001b[37m# and use sagemaker-containers defaults to set their values when not specified.\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--validation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_VALIDATION\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "\n",
      "    args = parser.parse_args()\n",
      "    \n",
      "    train(args.hp1, args.hp2, args.hp3, args.train, args.validation)\n"
     ]
    }
   ],
   "source": [
    "! pygmentize source_dir/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can realize that the training code has been implemented as a standard Python script, that will be invoked by the sagemaker-training-toolkit library passing hyperparameters as arguments. This way of invoking training script is indeed called <strong>Script Mode</strong> for Amazon SageMaker containers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we upload some dummy data to Amazon S3, in order to define our S3-based training channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'container_image_uri' (str)\n"
     ]
    }
   ],
   "source": [
    "container_image_uri = '057716757052.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-training-containers/tf-script-mode-container-2:latest'\n",
    "%store container_image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-northeast-2-057716757052/tf-script-mode-container-2/train/dummy.csv\n",
      "s3://sagemaker-ap-northeast-2-057716757052/tf-script-mode-container-2/val/dummy.csv\n"
     ]
    }
   ],
   "source": [
    "! echo \"val1, val2, val3\" > dummy.csv\n",
    "print(sagemaker_session.upload_data('dummy.csv', bucket, prefix + '/train'))\n",
    "print(sagemaker_session.upload_data('dummy.csv', bucket, prefix + '/val'))\n",
    "! rm dummy.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to dynamically run user-provided code loading it from Amazon S3, so we need to:\n",
    "<ul>\n",
    "    <li>Package the <strong>source_dir</strong> folder in a tar.gz archive</li>\n",
    "    <li>Upload the archive to Amazon S3</li>\n",
    "    <li>Specify the path to the archive in Amazon S3 as one of the parameters of the training job</li>\n",
    "</ul>\n",
    "\n",
    "<strong>Note:</strong> these steps are executed automatically by the Amazon SageMaker Python SDK when using framework estimators for MXNet, Tensorflow, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sourcedir.tar.gz'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "def create_tar_file(source_files, target=None):\n",
    "    if target:\n",
    "        filename = target\n",
    "    else:\n",
    "        _, filename = tempfile.mkstemp()\n",
    "\n",
    "    with tarfile.open(filename, mode=\"w:gz\") as t:\n",
    "        for sf in source_files:\n",
    "            # Add all files from the directory into the root of the directory structure of the tar\n",
    "            t.add(sf, arcname=os.path.basename(sf))\n",
    "    return filename\n",
    "\n",
    "create_tar_file([\"source_dir/train.py\", \"source_dir/utils.py\"], \"sourcedir.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-northeast-2-057716757052/tf-script-mode-container-2/code/sourcedir.tar.gz\n"
     ]
    }
   ],
   "source": [
    "sources = sagemaker_session.upload_data('sourcedir.tar.gz', bucket, prefix + '/code')\n",
    "print(sources)\n",
    "! rm sourcedir.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When starting the training job, we need to let the sagemaker-training-toolkit library know where the sources are stored in Amazon S3 and what is the module to be invoked. These parameters are specified through the following reserved hyperparameters (these reserved hyperparameters are injected automatically when using framework estimators of the Amazon SageMaker Python SDK):\n",
    "<ul>\n",
    "    <li>sagemaker_program</li>\n",
    "    <li>sagemaker_submit_directory</li>\n",
    "</ul>\n",
    "\n",
    "Finally, we can execute the training job by calling the fit() method of the generic Estimator object defined in the Amazon SageMaker Python SDK (https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/estimator.py). This corresponds to calling the CreateTrainingJob() API (https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateTrainingJob.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The class sagemaker.session.s3_input has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The class sagemaker.session.s3_input has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building with native build. Learn about native build in Compose here: https://docs.docker.com/go/compose-native-build/\n",
      "Creating p5o7iezr1v-algo-1-m9vgq ... \n",
      "Creating p5o7iezr1v-algo-1-m9vgq ... done\n",
      "Attaching to p5o7iezr1v-algo-1-m9vgq\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m 2021-02-25 09:39:40,135 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m 2021-02-25 09:39:40,144 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m 2021-02-25 09:39:40,153 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m 2021-02-25 09:39:40,162 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m \n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m Training Env:\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m \n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m {\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m         \"validation\": \"/opt/ml/input/data/validation\"\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     },\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     \"current_host\": \"algo-1-m9vgq\",\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     \"framework_module\": null,\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m         \"algo-1-m9vgq\"\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     ],\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m         \"hp1\": \"value1\",\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m         \"hp2\": 300,\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m         \"hp3\": 0.001\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     },\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m         \"train\": {\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m             \"TrainingInputMode\": \"File\",\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m             \"ContentType\": \"text/csv\"\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m         },\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m         \"validation\": {\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m             \"TrainingInputMode\": \"File\",\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m             \"ContentType\": \"text/csv\"\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m         }\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     },\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     \"job_name\": \"tf-script-mode-container-2-2021-02-25-09-39-38-122\",\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     \"master_hostname\": \"algo-1-m9vgq\",\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     \"module_dir\": \"s3://sagemaker-ap-northeast-2-057716757052/tf-script-mode-container-2/code/sourcedir.tar.gz\",\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     \"num_cpus\": 36,\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m         \"current_host\": \"algo-1-m9vgq\",\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m             \"algo-1-m9vgq\"\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m         ]\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     },\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m }\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m \n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m Environment variables:\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m \n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_HOSTS=[\"algo-1-m9vgq\"]\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_HPS={\"hp1\":\"value1\",\"hp2\":300,\"hp3\":0.001}\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-m9vgq\",\"hosts\":[\"algo-1-m9vgq\"]}\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_CHANNELS=[\"train\",\"validation\"]\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_CURRENT_HOST=algo-1-m9vgq\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_FRAMEWORK_MODULE=\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_NUM_CPUS=36\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_MODULE_DIR=s3://sagemaker-ap-northeast-2-057716757052/tf-script-mode-container-2/code/sourcedir.tar.gz\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-m9vgq\",\"framework_module\":null,\"hosts\":[\"algo-1-m9vgq\"],\"hyperparameters\":{\"hp1\":\"value1\",\"hp2\":300,\"hp3\":0.001},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tf-script-mode-container-2-2021-02-25-09-39-38-122\",\"log_level\":20,\"master_hostname\":\"algo-1-m9vgq\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-057716757052/tf-script-mode-container-2/code/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":36,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-m9vgq\",\"hosts\":[\"algo-1-m9vgq\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_USER_ARGS=[\"--hp1\",\"value1\",\"--hp2\",\"300\",\"--hp3\",\"0.001\"]\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_HP_HP1=value1\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_HP_HP2=300\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m SM_HP_HP3=0.001\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m \n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m \n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m /usr/bin/python3 train.py --hp1 value1 --hp2 300 --hp3 0.001\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m \n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m \n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m \n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m List of files in train channel: \n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m /opt/ml/input/data/train/dummy.csv\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m \n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m List of files in validation channel: \n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m /opt/ml/input/data/validation/dummy.csv\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m \n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m Running epoch 0...\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m Completed epoch 0.\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m \n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m Running epoch 1...\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m Completed epoch 1.\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m \n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m Running epoch 2...\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m Completed epoch 2.\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m \n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m Running epoch 3...\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m Completed epoch 3.\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m \n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m Running epoch 4...\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m Completed epoch 4.\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq |\u001b[0m 2021-02-25 09:42:10,347 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\u001b[36mp5o7iezr1v-algo-1-m9vgq exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import json\n",
    "\n",
    "# JSON encode hyperparameters.\n",
    "def json_encode_hyperparameters(hyperparameters):\n",
    "    return {str(k): json.dumps(v) for (k, v) in hyperparameters.items()}\n",
    "\n",
    "hyperparameters = json_encode_hyperparameters({\n",
    "    \"sagemaker_program\": \"train.py\",\n",
    "    \"sagemaker_submit_directory\": sources,\n",
    "    \"hp1\": \"value1\",\n",
    "    \"hp2\": 300,\n",
    "    \"hp3\": 0.001})\n",
    "\n",
    "est = sagemaker.estimator.Estimator(container_image_uri,\n",
    "                                    role,\n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='local',\n",
    "                                    base_job_name=prefix,\n",
    "                                    hyperparameters=hyperparameters)\n",
    "\n",
    "train_config = sagemaker.session.s3_input('s3://{0}/{1}/train/'.format(bucket, prefix), content_type='text/csv')\n",
    "val_config = sagemaker.session.s3_input('s3://{0}/{1}/val/'.format(bucket, prefix), content_type='text/csv')\n",
    "\n",
    "est.fit({'train': train_config, 'validation': val_config })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training with a custom SDK framework estimator</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you have seen, in the previous steps we had to upload our code to Amazon S3 and then inject reserved hyperparameters to execute training. In order to facilitate this task, you can also try defining a custom framework estimator using the Amazon SageMaker Python SDK and run training with that class, which will take care of managing these tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "image_name has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The class sagemaker.session.s3_input has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The class sagemaker.session.s3_input has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building with native build. Learn about native build in Compose here: https://docs.docker.com/go/compose-native-build/\n",
      "Creating ukrq6r9sfa-algo-1-hag6w ... \n",
      "Creating ukrq6r9sfa-algo-1-hag6w ... done\n",
      "Attaching to ukrq6r9sfa-algo-1-hag6w\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m 2021-02-25 09:42:13,025 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m 2021-02-25 09:42:13,034 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m 2021-02-25 09:42:13,043 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m 2021-02-25 09:42:13,053 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m \n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m Training Env:\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m \n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m {\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m         \"validation\": \"/opt/ml/input/data/validation\"\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     },\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     \"current_host\": \"algo-1-hag6w\",\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     \"framework_module\": null,\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m         \"algo-1-hag6w\"\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     ],\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m         \"hp1\": \"value1\",\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m         \"hp2\": \"300\",\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m         \"hp3\": \"0.001\"\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     },\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m         \"train\": {\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m             \"TrainingInputMode\": \"File\",\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m             \"ContentType\": \"text/csv\"\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m         },\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m         \"validation\": {\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m             \"TrainingInputMode\": \"File\",\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m             \"ContentType\": \"text/csv\"\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m         }\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     },\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     \"job_name\": \"tf-script-mode-container-2-2021-02-25-09-42-10-934\",\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     \"master_hostname\": \"algo-1-hag6w\",\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     \"module_dir\": \"s3://sagemaker-ap-northeast-2-057716757052/tf-script-mode-container-2-2021-02-25-09-42-10-934/source/sourcedir.tar.gz\",\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     \"num_cpus\": 36,\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m         \"current_host\": \"algo-1-hag6w\",\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m             \"algo-1-hag6w\"\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m         ]\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     },\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m }\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m \n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m Environment variables:\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m \n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_HOSTS=[\"algo-1-hag6w\"]\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_HPS={\"hp1\":\"value1\",\"hp2\":\"300\",\"hp3\":\"0.001\"}\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-hag6w\",\"hosts\":[\"algo-1-hag6w\"]}\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_CHANNELS=[\"train\",\"validation\"]\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_CURRENT_HOST=algo-1-hag6w\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_FRAMEWORK_MODULE=\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_NUM_CPUS=36\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_MODULE_DIR=s3://sagemaker-ap-northeast-2-057716757052/tf-script-mode-container-2-2021-02-25-09-42-10-934/source/sourcedir.tar.gz\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-hag6w\",\"framework_module\":null,\"hosts\":[\"algo-1-hag6w\"],\"hyperparameters\":{\"hp1\":\"value1\",\"hp2\":\"300\",\"hp3\":\"0.001\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tf-script-mode-container-2-2021-02-25-09-42-10-934\",\"log_level\":20,\"master_hostname\":\"algo-1-hag6w\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-057716757052/tf-script-mode-container-2-2021-02-25-09-42-10-934/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":36,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-hag6w\",\"hosts\":[\"algo-1-hag6w\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_USER_ARGS=[\"--hp1\",\"value1\",\"--hp2\",\"300\",\"--hp3\",\"0.001\"]\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_HP_HP1=value1\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_HP_HP2=300\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m SM_HP_HP3=0.001\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m \n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m \n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m /usr/bin/python3 train.py --hp1 value1 --hp2 300 --hp3 0.001\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m \n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m \n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m \n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m List of files in train channel: \n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m /opt/ml/input/data/train/dummy.csv\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m \n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m List of files in validation channel: \n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m /opt/ml/input/data/validation/dummy.csv\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m \n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m Running epoch 0...\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m Completed epoch 0.\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m \n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m Running epoch 1...\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m Completed epoch 1.\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m \n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m Running epoch 2...\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m Completed epoch 2.\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m \n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m Running epoch 3...\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m Completed epoch 3.\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m \n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m Running epoch 4...\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m Completed epoch 4.\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w |\u001b[0m 2021-02-25 09:44:43,237 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\u001b[36mukrq6r9sfa-algo-1-hag6w exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Framework\n",
    "\n",
    "class CustomFramework(Framework):\n",
    "    def __init__(\n",
    "        self,\n",
    "        entry_point,\n",
    "        source_dir=None,\n",
    "        hyperparameters=None,\n",
    "        py_version=\"py3\",\n",
    "        framework_version=None,\n",
    "        image_name=None,\n",
    "        distributions=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(CustomFramework, self).__init__(\n",
    "            entry_point, source_dir, hyperparameters, image_name=image_name, **kwargs\n",
    "        )\n",
    "    \n",
    "    def _configure_distribution(self, distributions):\n",
    "        return\n",
    "    \n",
    "    def create_model(\n",
    "        self,\n",
    "        model_server_workers=None,\n",
    "        role=None,\n",
    "        vpc_config_override=None,\n",
    "        entry_point=None,\n",
    "        source_dir=None,\n",
    "        dependencies=None,\n",
    "        image_name=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        return None\n",
    "        \n",
    "import sagemaker\n",
    "\n",
    "est = CustomFramework(image_name=container_image_uri,\n",
    "                      role=role,\n",
    "                      entry_point='train.py',\n",
    "                      source_dir='source_dir/',\n",
    "                      train_instance_count=1, \n",
    "                      train_instance_type='local', # we use local mode\n",
    "                      #train_instance_type='ml.m5.xlarge',\n",
    "                      base_job_name=prefix,\n",
    "                      hyperparameters={\n",
    "                          \"hp1\": \"value1\",\n",
    "                          \"hp2\": \"300\",\n",
    "                          \"hp3\": \"0.001\"\n",
    "                      })\n",
    "\n",
    "train_config = sagemaker.session.s3_input('s3://{0}/{1}/train/'.format(bucket, prefix), content_type='text/csv')\n",
    "val_config = sagemaker.session.s3_input('s3://{0}/{1}/val/'.format(bucket, prefix), content_type='text/csv')\n",
    "\n",
    "est.fit({'train': train_config, 'validation': val_config })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test in Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "image_name has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The class sagemaker.session.s3_input has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The class sagemaker.session.s3_input has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-25 09:50:23 Starting - Starting the training job...\n",
      "2021-02-25 09:50:49 Starting - Launching requested ML instancesProfilerReport-1614246623: InProgress\n",
      "......\n",
      "2021-02-25 09:51:50 Starting - Preparing the instances for training...\n",
      "2021-02-25 09:52:19 Downloading - Downloading input data...\n",
      "2021-02-25 09:52:51 Training - Downloading the training image........\u001b[34m2021-02-25 09:54:03,194 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34m/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\u001b[0m\n",
      "\u001b[34m/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\u001b[0m\n",
      "\u001b[34mCollecting pandas<2\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\u001b[0m\n",
      "\u001b[34mCollecting pytz>=2017.2\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas<2->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas<2->-r requirements.txt (line 1)) (1.18.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas<2->-r requirements.txt (line 1)) (1.14.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pytz, pandas\u001b[0m\n",
      "\u001b[34mSuccessfully installed pandas-1.1.5 pytz-2021.1\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 20.0.2; however, version 21.0.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2021-02-25 09:54:09,818 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-02-25 09:54:09,829 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-02-25 09:54:09,840 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-02-25 09:54:09,851 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"hp1\": \"value1\",\n",
      "        \"hp3\": \"0.001\",\n",
      "        \"hp2\": \"300\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"validation\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tf-script-mode-container-2-2021-02-25-09-50-23-387\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-northeast-2-057716757052/tf-script-mode-container-2-2021-02-25-09-50-23-387/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"hp1\":\"value1\",\"hp2\":\"300\",\"hp3\":\"0.001\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-northeast-2-057716757052/tf-script-mode-container-2-2021-02-25-09-50-23-387/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"hp1\":\"value1\",\"hp2\":\"300\",\"hp3\":\"0.001\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tf-script-mode-container-2-2021-02-25-09-50-23-387\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-057716757052/tf-script-mode-container-2-2021-02-25-09-50-23-387/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--hp1\",\"value1\",\"--hp2\",\"300\",\"--hp3\",\"0.001\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_HP1=value1\u001b[0m\n",
      "\u001b[34mSM_HP_HP3=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_HP2=300\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 train.py --hp1 value1 --hp2 300 --hp3 0.001\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "2021-02-25 09:54:12 Training - Training image download completed. Training in progress.\u001b[34mList of files in train channel: \u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/train/dummy.csv\n",
      "\u001b[0m\n",
      "\u001b[34mList of files in validation channel: \u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/validation/dummy.csv\n",
      "\u001b[0m\n",
      "\u001b[34mRunning epoch 0...\u001b[0m\n",
      "\u001b[34mCompleted epoch 0.\n",
      "\u001b[0m\n",
      "\u001b[34mRunning epoch 1...\u001b[0m\n",
      "\u001b[34mCompleted epoch 1.\n",
      "\u001b[0m\n",
      "\u001b[34mRunning epoch 2...\u001b[0m\n",
      "\u001b[34mCompleted epoch 2.\n",
      "\u001b[0m\n",
      "\u001b[34mRunning epoch 3...\u001b[0m\n",
      "\u001b[34mCompleted epoch 3.\n",
      "\u001b[0m\n",
      "\u001b[34mRunning epoch 4...\u001b[0m\n",
      "\u001b[34mCompleted epoch 4.\u001b[0m\n",
      "\u001b[34m2021-02-25 09:56:40,021 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-02-25 09:56:54 Uploading - Uploading generated training model\n",
      "2021-02-25 09:56:54 Completed - Training job completed\n",
      "Training seconds: 270\n",
      "Billable seconds: 270\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Framework\n",
    "\n",
    "class CustomFramework(Framework):\n",
    "    def __init__(\n",
    "        self,\n",
    "        entry_point,\n",
    "        source_dir=None,\n",
    "        hyperparameters=None,\n",
    "        py_version=\"py3\",\n",
    "        framework_version=None,\n",
    "        image_name=None,\n",
    "        distributions=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(CustomFramework, self).__init__(\n",
    "            entry_point, source_dir, hyperparameters, image_name=image_name, **kwargs\n",
    "        )\n",
    "    \n",
    "    def _configure_distribution(self, distributions):\n",
    "        return\n",
    "    \n",
    "    def create_model(\n",
    "        self,\n",
    "        model_server_workers=None,\n",
    "        role=None,\n",
    "        vpc_config_override=None,\n",
    "        entry_point=None,\n",
    "        source_dir=None,\n",
    "        dependencies=None,\n",
    "        image_name=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        return None\n",
    "        \n",
    "import sagemaker\n",
    "\n",
    "est = CustomFramework(image_name=container_image_uri,\n",
    "                      role=role,\n",
    "                      entry_point='train.py',\n",
    "                      source_dir='source_dir/',\n",
    "                      train_instance_count=1, \n",
    "                      # train_instance_type='local', # we use local mode\n",
    "                      train_instance_type='ml.m5.xlarge',\n",
    "                      base_job_name=prefix,\n",
    "                      hyperparameters={\n",
    "                          \"hp1\": \"value1\",\n",
    "                          \"hp2\": \"300\",\n",
    "                          \"hp3\": \"0.001\"\n",
    "                      })\n",
    "\n",
    "train_config = sagemaker.session.s3_input('s3://{0}/{1}/train/'.format(bucket, prefix), content_type='text/csv')\n",
    "val_config = sagemaker.session.s3_input('s3://{0}/{1}/val/'.format(bucket, prefix), content_type='text/csv')\n",
    "\n",
    "est.fit({'train': train_config, 'validation': val_config })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
